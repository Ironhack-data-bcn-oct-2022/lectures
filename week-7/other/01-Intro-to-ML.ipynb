{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4737e761",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "# Intro to Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-american",
   "metadata": {},
   "source": [
    "![elgifderigor](https://media.giphy.com/media/NsBknNwmmWE8WU1q2U/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-vault",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Some-concepts\" data-toc-modified-id=\"Some-concepts-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Some concepts</a></span><ul class=\"toc-item\"><li><span><a href=\"#Estimators\" data-toc-modified-id=\"Estimators-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Estimators</a></span></li><li><span><a href=\"#Bias-Error\" data-toc-modified-id=\"Bias-Error-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Bias Error</a></span></li><li><span><a href=\"#Variance-Error\" data-toc-modified-id=\"Variance-Error-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Variance Error</a></span></li></ul></li><li><span><a href=\"#Types-of-Machine-Learning\" data-toc-modified-id=\"Types-of-Machine-Learning-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Types of Machine Learning</a></span></li><li><span><a href=\"#Features\" data-toc-modified-id=\"Features-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Features</a></span></li><li><span><a href=\"#Underfitting-and-Overfitting\" data-toc-modified-id=\"Underfitting-and-Overfitting-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Underfitting and Overfitting</a></span></li><li><span><a href=\"#Let's-do-it?\" data-toc-modified-id=\"Let's-do-it?-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Let's do it?</a></span><ul class=\"toc-item\"><li><span><a href=\"#Let's-practice-ML-with-a-regression-example\" data-toc-modified-id=\"Let's-practice-ML-with-a-regression-example-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Let's practice ML with a regression example</a></span></li><li><span><a href=\"#We-load-a-dataset\" data-toc-modified-id=\"We-load-a-dataset-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>We load a dataset</a></span></li><li><span><a href=\"#Train-/-Test-Split---What-is-this?\" data-toc-modified-id=\"Train-/-Test-Split---What-is-this?-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Train / Test Split - What is this?</a></span></li><li><span><a href=\"#Preparing-data-for-train-test-split\" data-toc-modified-id=\"Preparing-data-for-train-test-split-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Preparing data for train test split</a></span></li><li><span><a href=\"#Optional-train-test-split-parameters\" data-toc-modified-id=\"Optional-train-test-split-parameters-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Optional train test split parameters</a></span></li><li><span><a href=\"#We-already-have-the-dataset-divided,-now-we-are-going-to-import-a-model-and-train-it\" data-toc-modified-id=\"We-already-have-the-dataset-divided,-now-we-are-going-to-import-a-model-and-train-it-5.6\"><span class=\"toc-item-num\">5.6&nbsp;&nbsp;</span>We already have the dataset divided, now we are going to import a model and train it</a></span></li><li><span><a href=\"#We-create-our-predictions\" data-toc-modified-id=\"We-create-our-predictions-5.7\"><span class=\"toc-item-num\">5.7&nbsp;&nbsp;</span>We create our predictions</a></span></li><li><span><a href=\"#We-measure-our-model\" data-toc-modified-id=\"We-measure-our-model-5.8\"><span class=\"toc-item-num\">5.8&nbsp;&nbsp;</span>We measure our model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Example-with-a-real-case-of-a-colleague-who-gives-me-data-from-a-house-in-Boston\" data-toc-modified-id=\"Example-with-a-real-case-of-a-colleague-who-gives-me-data-from-a-house-in-Boston-5.8.1\"><span class=\"toc-item-num\">5.8.1&nbsp;&nbsp;</span>Example with a real case of a colleague who gives me data from a house in Boston</a></span></li></ul></li></ul></li><li><span><a href=\"#Extra!-Training-different-models-at-the-same-time\" data-toc-modified-id=\"Extra!-Training-different-models-at-the-same-time-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Extra! Training different models at the same time</a></span><ul class=\"toc-item\"><li><span><a href=\"#Store-all-the-models-we-are-going-to-train-in-a-dictionary\" data-toc-modified-id=\"Store-all-the-models-we-are-going-to-train-in-a-dictionary-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Store all the models we are going to train in a dictionary</a></span></li><li><span><a href=\"#Iterate-over-the-models-to-train-them\" data-toc-modified-id=\"Iterate-over-the-models-to-train-them-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Iterate over the models to train them</a></span></li></ul></li><li><span><a href=\"#Feature-Selection\" data-toc-modified-id=\"Feature-Selection-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Feature Selection</a></span><ul class=\"toc-item\"><li><span><a href=\"#We-make-CV-to-a-single-model\" data-toc-modified-id=\"We-make-CV-to-a-single-model-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>We make CV to a single model</a></span></li><li><span><a href=\"#CV-looping-through-all-models\" data-toc-modified-id=\"CV-looping-through-all-models-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>CV looping through all models</a></span></li></ul></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Summary</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe8bdd5",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Some concepts\n",
    "To understand how a machine learning algorithm learns from data to predict an outcome, it is essential to understand the underlying concepts that go into training an algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab999f7d",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Estimators\n",
    "Estimate is a statistical term for finding some estimate of an unknown parameter, given some data. Point estimation is the attempt to provide the best prediction of some quantity of interest.\n",
    "The amount of interest can be:\n",
    " - A single parameter\n",
    " - A vector of parameters - for example, the weights in linear regression\n",
    " - A full function\n",
    "\n",
    "### Bias Error\n",
    "\n",
    "It is the difference between the expected prediction of our model and the true values. Although in the end our goal is always to build models that can predict data very close to the true values, it is not always that easy because some algorithms are simply too rigid to learn complex signals from the data set.\n",
    "\n",
    "Imagine fitting a linear regression to a data set that has a non-linear pattern, no matter how many more observations you collect, a linear regression will not be able to model the curves on that data. This is known as underfitting.\n",
    "\n",
    "In general, parametric algorithms like linear regression have a high bias that makes them quick to learn and easier to understand, but generally less flexible. In turn, they have a lower predictive performance in complex problems.\n",
    "\n",
    "### Variance Error\n",
    "\n",
    "It refers to the amount that the estimate of the objective function will change if different training data is used. The objective function is estimated from the training data by a Machine Learning algorithm, so we should expect the algorithm to have some variance. Ideally it shouldn't change too much from one training dataset to another, which means the algorithm is good at choosing the hidden underlying mapping between the input and output variables.\n",
    "\n",
    "Machine learning algorithms that have a large variance are heavily influenced by the details of the training data, this means that the details of the training influence the number and types of parameters used to characterize the mapping function.\n",
    "\n",
    "Generally, non-parametric machine learning algorithms that have a lot of flexibility have a lot of variation.\n",
    "\n",
    "- Low variance: suggests small changes in the estimate of the objective function with changes in the training data set.\n",
    "- High variance: suggests large changes in the estimate of the objective function with changes in the training data set.\n",
    "Low variance machine learning algorithms include: linear regression, linear discriminant analysis, and logistic regression.\n",
    "\n",
    "On the other hand, the algorithms with high variance are: decision trees, k-nearest neighbors and support vector machines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee9c76",
   "metadata": {},
   "source": [
    "<img src=\"https://nvsyashwanth.github.io/machinelearningmaster/assets/images/bias_variance.jpg\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b75a54",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Types of Machine Learning\n",
    "- **Supervised**\n",
    "The model is trained with labeled data, that is, with data whose basic truth is known. When presented with data and a label, the model infers patterns.\n",
    "\n",
    "- **Unsupervised**\n",
    "There are no basic truths. The model looks for previously undetected patterns, with which to separate the different data points into different clusters.\n",
    "\n",
    "- **Reinforcement**\n",
    "There is also no basic truth. The model's action is valued and a reward or punishment is given accordingly. The goal of the model is to get as many rewards as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794bb12e",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Features\n",
    "- **Features** are independent individual variables that act as input to your system. Prediction models use features to\n",
    "make predictions.\n",
    "\n",
    "- **Target**\n",
    "The goal is the output of the input variables. They can be the individual classes to which the input variables are assigned in the case of a classification problem or the range of output values ​​in a regression problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69f061c",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Underfitting and Overfitting\n",
    "Splitting a data set can also be important to detect if your model suffers from one of two common problems, called underfitting and overfitting:\n",
    "\n",
    "- **Underfitting** is usually the consequence of a model being unable to encapsulate relationships between data. For example, this can occur when trying to represent nonlinear relationships with a linear model. Underfitted models are likely to perform poorly on both the training and test sets.\n",
    "\n",
    "\n",
    "- **Overfitting** usually occurs when a model has an excessively complex structure and learns both relationships between data and noise. These models tend to have poor generalization ability. Although they work well with training data, they tend to perform poorly with unseen (test) data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42891daf",
   "metadata": {},
   "source": [
    "<img src=\"https://community.alteryx.com/t5/image/serverpage/image-id/52874iE986B6E19F3248CF?v=v2\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d818b71",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Bias and variance in machine learning --> https://www.analyticslane.com/2019/05/24/the-concepts-of-bias-and-variance-in-machine-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bb69f4",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Let's do it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cc9340",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Let's practice ML with a regression example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d349a945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "legitimate-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d3c508",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### We load a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29aba32f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load_boston in module sklearn.datasets._base:\n",
      "\n",
      "load_boston(*, return_X_y=False)\n",
      "    DEPRECATED: `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "    \n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "    \n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "    \n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "    \n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "    \n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "    \n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "    \n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "    \n",
      "    for the California housing dataset and::\n",
      "    \n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "    \n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "    Load and return the Boston house-prices dataset (regression).\n",
      "    \n",
      "    ==============   ==============\n",
      "    Samples total               506\n",
      "    Dimensionality               13\n",
      "    Features         real, positive\n",
      "    Targets           real 5. - 50.\n",
      "    ==============   ==============\n",
      "    \n",
      "    Read more in the :ref:`User Guide <boston_dataset>`.\n",
      "    \n",
      "    .. warning::\n",
      "        The Boston housing prices dataset has an ethical problem: as\n",
      "        investigated in [1]_, the authors of this dataset engineered a\n",
      "        non-invertible variable \"B\" assuming that racial self-segregation had a\n",
      "        positive impact on house prices [2]_. Furthermore the goal of the\n",
      "        research that led to the creation of this dataset was to study the\n",
      "        impact of air quality but it did not give adequate demonstration of the\n",
      "        validity of this assumption.\n",
      "    \n",
      "        The scikit-learn maintainers therefore strongly discourage the use of\n",
      "        this dataset unless the purpose of the code is to study and educate\n",
      "        about ethical issues in data science and machine learning.\n",
      "    \n",
      "        In this special case, you can fetch the dataset from the original\n",
      "        source::\n",
      "    \n",
      "            import pandas as pd  # doctest: +SKIP\n",
      "            import numpy as np\n",
      "    \n",
      "            data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "            raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "            data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "            target = raw_df.values[1::2, 2]\n",
      "    \n",
      "        Alternative datasets include the California housing dataset [3]_\n",
      "        (i.e. :func:`~sklearn.datasets.fetch_california_housing`) and Ames\n",
      "        housing dataset [4]_. You can load the datasets as follows::\n",
      "    \n",
      "            from sklearn.datasets import fetch_california_housing\n",
      "            housing = fetch_california_housing()\n",
      "    \n",
      "        for the California housing dataset and::\n",
      "    \n",
      "            from sklearn.datasets import fetch_openml\n",
      "            housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "    \n",
      "        for the Ames housing dataset.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    return_X_y : bool, default=False\n",
      "        If True, returns ``(data, target)`` instead of a Bunch object.\n",
      "        See below for more information about the `data` and `target` object.\n",
      "    \n",
      "        .. versionadded:: 0.18\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    data : :class:`~sklearn.utils.Bunch`\n",
      "        Dictionary-like object, with the following attributes.\n",
      "    \n",
      "        data : ndarray of shape (506, 13)\n",
      "            The data matrix.\n",
      "        target : ndarray of shape (506,)\n",
      "            The regression target.\n",
      "        filename : str\n",
      "            The physical location of boston csv dataset.\n",
      "    \n",
      "            .. versionadded:: 0.20\n",
      "    \n",
      "        DESCR : str\n",
      "            The full description of the dataset.\n",
      "        feature_names : ndarray\n",
      "            The names of features\n",
      "    \n",
      "    (data, target) : tuple if ``return_X_y`` is True\n",
      "        A tuple of two ndarrays. The first contains a 2D array of shape (506, 13)\n",
      "        with each row representing one sample and each column representing the features.\n",
      "        The second array of shape (506,) contains the target samples.\n",
      "    \n",
      "        .. versionadded:: 0.18\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "        .. versionchanged:: 0.20\n",
      "            Fixed a wrong data point at [445, 0].\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] `Racist data destruction? M Carlisle,\n",
      "            <https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>`_\n",
      "    .. [2] `Harrison Jr, David, and Daniel L. Rubinfeld.\n",
      "           \"Hedonic housing prices and the demand for clean air.\"\n",
      "           Journal of environmental economics and management 5.1 (1978): 81-102.\n",
      "           <https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>`_\n",
      "    .. [3] `California housing dataset\n",
      "            <https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset>`_\n",
      "    .. [4] `Ames housing dataset\n",
      "            <https://www.openml.org/d/42165>`_\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import warnings\n",
      "    >>> from sklearn.datasets import load_boston\n",
      "    >>> with warnings.catch_warnings():\n",
      "    ...     # You should probably not use this dataset.\n",
      "    ...     warnings.filterwarnings(\"ignore\")\n",
      "    ...     X, y = load_boston(return_X_y=True)\n",
      "    >>> print(X.shape)\n",
      "    (506, 13)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(load_boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "respiratory-elite",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = pd.DataFrame(load_boston().data, columns=load_boston().feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb8eb559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a28770f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston[\"MEDV\"] = load_boston().target # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "494f3c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a57701d",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Train / Test Split - What is this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75e15f7",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dataquest.io/wp-content/uploads/kaggle_train_test_split.svg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ab1891",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "The training-test split is a technique for evaluating the performance of a machine learning algorithm.\n",
    "\n",
    "It can be used for classification or regression problems and can be used for any supervised learning algorithm.\n",
    "\n",
    "The procedure consists of taking a data set and dividing it into two subsets. The first subset is used to fit the model and is called the training data set. The second subset is not used to train the model; instead, the model is given the input from the dataset, then predictions are made and compared to expected values. This second data set is called the test data set.\n",
    "\n",
    "Training dataset: Used to fit the machine learning model.\n",
    "Test dataset: Used to evaluate the fitted machine learning model.\n",
    "The goal is to estimate the performance of the machine learning model with new data: data not used to train the model.\n",
    "\n",
    "This is how we hope to use the model in practice. That is, fit it on the available data with known inputs and outputs, and then make predictions about new examples in the future where we don't have the expected output or target values.\n",
    "\n",
    "The training-test procedure is adequate when a sufficiently large data set is available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b7641d",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Preparing data for train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "automatic-adoption",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
       "       'PTRATIO', 'B', 'LSTAT', 'MEDV'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dbb085c",
   "metadata": {
    "lang": "en"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = boston.drop(\"MEDV\", axis=1) #The X is always a dataframe (Even if it only has one column)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d527611d",
   "metadata": {
    "lang": "en"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24.0\n",
       "1    21.6\n",
       "2    34.7\n",
       "3    33.4\n",
       "4    36.2\n",
       "Name: MEDV, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = boston.MEDV #La y is always A PANDAS SERIES\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "closed-wellington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "intensive-newark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd02e98",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Optional train test split parameters\n",
    "\n",
    "- **`train_size`** is the number that defines the size of the training set. If you provide a float then it must be between 0.0 and 1.0 and will define the part of the dataset used for testing. If you provide an int, then it will represent the total number of training samples. The default value is None.\n",
    "\n",
    "- **`test_size`** is the number that defines the size of the test suite. It is very similar to train_size. You must provide either train_size or test_size. If neither is provided, the default portion of the dataset to use for testing is 0.25, or 25 percent.\n",
    "\n",
    "- **`random_state`** is the object that controls randomness during splitting. It can be an int or an instance of RandomState. The default value is None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "private-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4aeb0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(tts) # sklearn help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "hybrid-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = tts(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "flying-alpha",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "comic-brown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 13)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "destroyed-velvet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "digital-bradley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2813454a",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### We already have the dataset divided, now we are going to import a model and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ultimate-tumor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression as LinReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "manual-salmon",
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg=LinReg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "406734a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "small-sessions",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.fit(X_train, y_train) # Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d1f7ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.25546425e-01,  4.80526273e-02,  4.77534406e-03,  2.78292708e+00,\n",
       "       -1.57625323e+01,  4.10384314e+00, -8.83064530e-03, -1.48642629e+00,\n",
       "        3.15230956e-01, -1.39024146e-02, -8.68109730e-01,  9.37030005e-03,\n",
       "       -4.68757235e-01])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.coef_ # betas coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96b4b4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.762655041306196"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5570f80d",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### We create our predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "executed-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "single-johnson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e96d06c",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### We measure our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "treated-remedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ordered-nickel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE - Mean absolute error 3.1990164957150267\n",
      "MSE - Mean squared error 22.948748187750336\n",
      "RMSE - Root mean squared error 4.790485172479959\n",
      "R2 - Coefficient of determination 0.7279325655991955\n"
     ]
    }
   ],
   "source": [
    "print('MAE - Mean absolute error', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('MSE - Mean squared error', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('RMSE - Root mean squared error', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print('R2 - Coefficient of determination', metrics.r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "253b8834",
   "metadata": {
    "lang": "en"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM         0.57529\n",
       "ZN           0.00000\n",
       "INDUS        6.20000\n",
       "CHAS         0.00000\n",
       "NOX          0.50700\n",
       "RM           8.33700\n",
       "AGE         73.30000\n",
       "DIS          3.83840\n",
       "RAD          8.00000\n",
       "TAX        307.00000\n",
       "PTRATIO     17.40000\n",
       "B          385.91000\n",
       "LSTAT        2.47000\n",
       "Name: 232, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[0] #Example of a sample of my data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fae727",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "#### Example with a real case of a colleague who gives me data from a house in Boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4e5de65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{\"CRIM\": 0.247, \"ZN\": 0.0000, \"INDUS\": 5.266, \"CHAS\": 0.001, \"NOX\": 0.429, \"RM\": 7.943, \"AGE\": 50, \"DIS\": 2.15, \"RAD\":7.0000, \"TAX\": 503.25, \"PTRATIO\": 19.252, \"B\": 420.35, \"LSTAT\": 7.6}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a1787e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f6051bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.266</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.429</td>\n",
       "      <td>7.943</td>\n",
       "      <td>50</td>\n",
       "      <td>2.15</td>\n",
       "      <td>7.0</td>\n",
       "      <td>503.25</td>\n",
       "      <td>19.252</td>\n",
       "      <td>420.35</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CRIM   ZN  INDUS   CHAS    NOX     RM  AGE   DIS  RAD     TAX  PTRATIO  \\\n",
       "0  0.247  0.0  5.266  0.001  0.429  7.943   50  2.15  7.0  503.25   19.252   \n",
       "\n",
       "        B  LSTAT  \n",
       "0  420.35    7.6  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e91992d1",
   "metadata": {
    "lang": "en"
   },
   "outputs": [],
   "source": [
    "price = linreg.predict(new) # I GET THE PREDICTION WITH MY NEW DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b4ba65b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33.83055452])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd821128",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Extra! Training different models at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ec1560",
   "metadata": {},
   "source": [
    "- [SKlearn - Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)\n",
    "- [SKlearn - Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html?highlight=lasso#sklearn.linear_model.Lasso)\n",
    "- [SKlearn - SGD Regressor](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html)\n",
    "- [SKlearn - KNeighbours](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "- [SKlearn - GradientBoostingRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html)\n",
    "- [SKlearn - SVR](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "designed-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b63a201",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Store all the models we are going to train in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36fb5481",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'ridge': Ridge(),\n",
    "    'lasso': Lasso(),\n",
    "    'sgd': SGDRegressor(),\n",
    "    'knn': KNeighborsRegressor(),\n",
    "    'grad': GradientBoostingRegressor(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "afd962c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1303a642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.linear_model._ridge.Ridge"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e8c182",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Iterate over the models to train them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8438c17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 🏋️‍♀️:  ridge\n",
      "Training 🏋️‍♀️:  lasso\n",
      "Training 🏋️‍♀️:  sgd\n",
      "Training 🏋️‍♀️:  knn\n",
      "Training 🏋️‍♀️:  grad\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    print(\"Training 🏋️‍♀️: \", name)\n",
    "    model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dec20226",
   "metadata": {
    "lang": "en"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ridge------\n",
      "MAE -  3.2488989854329575\n",
      "MSE -  23.471782243089603\n",
      "RMSE -  4.844768543809869\n",
      "R2 -  0.7217317683977011\n",
      "------lasso------\n",
      "MAE -  3.7506318106230063\n",
      "MSE -  26.407376998936343\n",
      "RMSE -  5.138810854559287\n",
      "R2 -  0.6869290102198062\n",
      "------sgd------\n",
      "MAE -  256412889944270.16\n",
      "MSE -  7.098130245723041e+28\n",
      "RMSE -  266423164265479.0\n",
      "R2 -  -8.415143471866784e+26\n",
      "------knn------\n",
      "MAE -  4.398235294117647\n",
      "MSE -  35.20094509803922\n",
      "RMSE -  5.933038437262919\n",
      "R2 -  0.5826774191361268\n",
      "------grad------\n",
      "MAE -  2.0480367550963297\n",
      "MSE -  6.984801078227538\n",
      "RMSE -  2.642877423988396\n",
      "R2 -  0.9171921320672425\n"
     ]
    }
   ],
   "source": [
    "# We can follow the same process to make predictions from each algorithm and get metrics\n",
    "for name, model in models.items():z5\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"------{name}------\")\n",
    "    print('MAE - ', metrics.mean_absolute_error(y_test, y_pred))\n",
    "    print('MSE - ', metrics.mean_squared_error(y_test, y_pred))\n",
    "    print('RMSE - ', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    print('R2 - ', metrics.r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b316de47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(GradientBoostingRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18ea72b",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "003082cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ecdf71",
   "metadata": {},
   "source": [
    "[Docs](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fca4400",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Given an external estimator that assigns weights to features (for example, the coefficients of a linear model), the goal of recursive feature elimination (RFE) is to select them by recursively considering smaller and smaller sets of features. First, the estimator is trained with the initial set of features and the importance of each of them is obtained through some specific or callable attribute. The less important features of the current set are then removed. This procedure is repeated recursively on the pruned set until the desired number of features to select is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6b1a62df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False,  True,  True,  True, False,  True, False,\n",
       "       False,  True, False, False])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = SVR(kernel=\"linear\")\n",
    "selector = RFE(estimator, n_features_to_select=5, step=1)\n",
    "selector = selector.fit(X_test, y_test)\n",
    "selector.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c78ccb3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 8, 4, 1, 1, 1, 6, 1, 3, 9, 1, 7, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2625af8c",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "The ranking of the features, so that ranking_[i] corresponds to the ranking position of the i-th feature. Selected features (i.e. best estimates) are assigned rank 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "69b985e8",
   "metadata": {
    "lang": "en"
   },
   "outputs": [],
   "source": [
    "# The metrics for cross validation are R2 for regression and Accuracy for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-walnut",
   "metadata": {},
   "source": [
    "![kfoldcv](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825c9d4d",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Cross-Validation: K-fold with 5 splits\n",
    "What we normally do when training the model is to pass all the records to it and have it do the fit().\n",
    "With K-Folds -in this example of 5 splits- to train, instead of passing all the records directly to the model, we will do this:\n",
    "\n",
    "**Iterate 5 times:**\n",
    "- We will set aside 1/5 of samples\n",
    "- We train the model with the remaining 4/5 samples\n",
    "- We will measure the r2 obtained on those we had set aside.\n",
    "- This means that we do 5 independent workouts.\n",
    "- The final R2 will be the average of the 5 previous R2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae76a93",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### We make CV to a single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "joined-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score as cvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "476c5f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ridge': Ridge(),\n",
       " 'lasso': Lasso(),\n",
       " 'sgd': SGDRegressor(),\n",
       " 'knn': KNeighborsRegressor(),\n",
       " 'grad': GradientBoostingRegressor()}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3ad2b23e",
   "metadata": {
    "lang": "en"
   },
   "outputs": [],
   "source": [
    "gradient = models[\"grad\"] # store the model in a variable that previously had it in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "beneficial-bulgarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cvs(gradient, X, y, scoring=\"r2\", cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "prostate-louis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80795678, 0.6457523 , 0.28269438])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "afraid-advocacy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5788011556510301"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76a1794",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### CV looping through all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "surprised-information",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo:  ridge Score:  0.3892175824102393\n",
      "Modelo:  lasso Score:  0.431848787926522\n",
      "Modelo:  sgd Score:  -3.517371768618188e+26\n",
      "Modelo:  knn Score:  -0.31501646812514134\n",
      "Modelo:  grad Score:  0.6760512717769519\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    scores = cvs(model, X, y, scoring='r2', cv=5)\n",
    "    print('Model: ', name, 'Score: ', np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ea6610",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f2158d",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "- Machine learning\n",
    "- train test split --> (X_train, y_train, X_test, y_test)\n",
    "- three types of ML (supervised, unsupervised, by reinforcement)\n",
    "- y_pred --> the predictions I make with the model (model.predict(X_test))\n",
    "- model.fit(X_train,y_train) --> learn the data\n",
    "- ground truth --> and my target variable, is what makes it SUPERVISED\n",
    "- most important features / characteristics (variables that most influence the explanation of my data)\n",
    "- target == and\n",
    "- X == all my features (columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "ironhack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "nbTranslate": {
   "displayLangs": [
    "en",
    "es"
   ],
   "hotkey": "alt-a",
   "langInMainMenu": true,
   "sourceLang": "es",
   "targetLang": "en",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
